{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v40z8HXr9qzX"
   },
   "source": [
    "# Optimization\n",
    "\n",
    "## 1d example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qVTmSOb9qzi"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def show_trace(res):\n",
    "    n = max(abs(min(res)), abs(max(res)))\n",
    "    f_line = np.arange(-n, n, 0.01)\n",
    "    plt.plot(f_line, [f(x) for x in f_line], label=\"x\")\n",
    "    plt.plot(res, [f(x) for x in res], '-o', label=\"f(x)\")\n",
    "    plt.legend()\n",
    "             \n",
    "\n",
    "def f(x):     return x**2  # objective function\n",
    "def gradf(x): return 2 * x # its derivative\n",
    "\n",
    "#c = 0.15 * math.pi\n",
    "#def f(x):     return x*math.cos(c * x)\n",
    "#def gradf(x): return math.cos(c * x) - c * x * math.sin(c * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdOiJ2MO9qz6"
   },
   "outputs": [],
   "source": [
    "#simple random search\n",
    "\n",
    "def rand(x0, x_low, x_high, steps):    \n",
    "    x = x0\n",
    "    best = f(x0)\n",
    "    results = [x]\n",
    "    results_error = [best]\n",
    "    for i in range(steps):\n",
    "        x_n = np.random.uniform(x_low, x_high)                \n",
    "        if f(x_n) < best:\n",
    "            x = x_n\n",
    "            best = f(x_n)\n",
    "        results.append(x)\n",
    "        results_error.append(best)\n",
    "    print ('x:    ' ,x)\n",
    "    print ('f(x): ', f(x))    \n",
    "    return results, results_error\n",
    "    \n",
    "steps = 10\n",
    "res_rand = rand(10, -10, 10, steps)\n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace(res_rand[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1])\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbTI5w_-9q0X"
   },
   "outputs": [],
   "source": [
    "#random search (incremental steps)\n",
    "def rand2(x0, r, steps):    \n",
    "    x = x0\n",
    "    best = f(x0)\n",
    "    results = [x]\n",
    "    results_error = [best]\n",
    "    for i in range(steps):\n",
    "        x_n = x + np.random.uniform(-r, r)        \n",
    "        if f(x_n) < best:\n",
    "            x = x_n\n",
    "            best = f(x_n)\n",
    "        results.append(x)\n",
    "        results_error.append(best)\n",
    "    print ('x:    ' ,x)\n",
    "    print ('f(x): ', f(x))    \n",
    "    return results, results_error\n",
    "\n",
    "res_rand2 = rand2(10, 1, steps)\n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace(res_rand2[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1], label=\"rand\")\n",
    "plt.plot (range(steps+1), res_rand2[1], label=\"randI\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGDs9OTC9q0s"
   },
   "outputs": [],
   "source": [
    "#gradient descent\n",
    "\n",
    "def gd(x0, eta, steps):\n",
    "    x = x0\n",
    "    results = [x]\n",
    "    results_error = [f(x)]\n",
    "    for i in range(steps):\n",
    "        x = x - eta * gradf(x)\n",
    "        results.append(x)\n",
    "        results_error.append(f(x))\n",
    "    print('x:    ', x)\n",
    "    print('f(x): ', f(x))\n",
    "    return results, results_error\n",
    "\n",
    "res_gd = gd(10, 0.2, steps)  #good\n",
    "#res_gd = gd(10, 0.02, steps) #too small\n",
    "#res_gd = gd(10, 0.8, steps)  #too large -- lucky\n",
    "#res_gd = gd(10, 1, steps)    #too large -- cycle\n",
    "#res_gd = gd(10, 1.01, steps) #much too large\n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace(res_gd[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1], label=\"rand\")\n",
    "plt.plot (range(steps+1), res_rand2[1], label=\"randI\")\n",
    "plt.plot (range(steps+1), res_gd[1], label=\"gd\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhpCYe3Vj_EK"
   },
   "source": [
    "## 2d example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzMHq8asj_EM"
   },
   "outputs": [],
   "source": [
    "def show_trace2d(res):\n",
    "    n = 10\n",
    "    x_line = np.arange(-n, n, 0.1)\n",
    "    y_line = np.arange(-n, n, 0.1)\n",
    "    X, Y = np.meshgrid(x_line, y_line)\n",
    "    F = f(X,Y)\n",
    "    cp = plt.contour(X,Y,F)\n",
    "    plt.clabel(cp, inline=True, fontsize=10)\n",
    "    plt.plot([i[0] for i in res], [i[1] for i in res], '-o')\n",
    "\n",
    "def f(x,y):     return x**2 + 2*y**2\n",
    "def gradf_x(x,y): return 2*x\n",
    "def gradf_y(x,y): return 4*y\n",
    "\n",
    "def rand_2d(x0, y0, x_low, x_high, y_low, y_high, steps):    \n",
    "    x = x0\n",
    "    y = y0\n",
    "    best = f(x0,y0)\n",
    "    results = [(x,y)]\n",
    "    results_error = [best]\n",
    "    for i in range(steps):\n",
    "        x_n = np.random.uniform(x_low, x_high)\n",
    "        y_n = np.random.uniform(y_low, y_high)\n",
    "        if f(x_n,y_n) < best:\n",
    "            x = x_n\n",
    "            y = y_n\n",
    "            best = f(x_n,y_n)\n",
    "        results.append((x,y))\n",
    "        results_error.append(best)\n",
    "    print ('x:      ' ,x)\n",
    "    print ('y:      ', y)\n",
    "    print ('f(x,y): ', f(x,y))    \n",
    "    return results, results_error\n",
    "\n",
    "def rand2(x0, y0, r, steps):    \n",
    "    x = x0\n",
    "    y = y0\n",
    "    best = f(x0,y0)\n",
    "    results = [(x,y)]\n",
    "    results_error = [best]\n",
    "    for i in range(steps):\n",
    "        x_n = x + np.random.uniform(-r, r)\n",
    "        y_n = y + np.random.uniform(-r, r)\n",
    "        if f(x_n,y_n) < best:\n",
    "            x = x_n\n",
    "            y = y_n\n",
    "            best = f(x_n, y_n)\n",
    "        results.append((x,y))\n",
    "        results_error.append(best)\n",
    "    print ('x:      ' ,x)\n",
    "    print ('y:      ', y)\n",
    "    print ('f(x,y): ', f(x,y))    \n",
    "    return results, results_error\n",
    "\n",
    "def gd_2d(x0, y0, eta, steps):\n",
    "    x = x0\n",
    "    y = y0\n",
    "    results = [(x,y)]\n",
    "    results_error = [f(x,y)]\n",
    "    for i in range(steps):\n",
    "        x -= eta * gradf_x(x,y)\n",
    "        y -= eta * gradf_y(x,y)\n",
    "        results.append((x,y))\n",
    "        results_error.append(f(x,y))\n",
    "    print('x:      ', x)\n",
    "    print('y:      ', y)\n",
    "    print('f(x,y): ', f(x,y))\n",
    "    return results, results_error\n",
    "\n",
    "\n",
    "steps= 100                       \n",
    "res_rand = rand_2d(10,10, -10, 10, -10, 10, steps)                       \n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace2d(res_rand[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1], label=\"rand\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");                       \n",
    "                       \n",
    "res_rand2 = rand2(10, 10, 2, steps)\n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace2d(res_rand2[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1], label=\"rand\")\n",
    "plt.plot (range(steps+1), res_rand2[1], label='randI')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");\n",
    "\n",
    "res_gd = gd_2d(10, 10, 0.05, steps)\n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace2d(res_gd[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1], label=\"rand\")\n",
    "plt.plot (range(steps+1), res_rand2[1], label='randI')\n",
    "plt.plot (range(steps+1), res_gd[1], label='gd')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "02_theory.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
