{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9962bab1-d50f-4ad7-9a7d-c4460ec20714",
      "metadata": {
        "id": "9962bab1-d50f-4ad7-9a7d-c4460ec20714"
      },
      "source": [
        "# Vision Transformer\n",
        "\n",
        "Based on https://keras.io/examples/vision/image_classification_with_vision_transformer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "aaff22a1-e8be-4e06-996f-57844c4a0cc3",
      "metadata": {
        "id": "aaff22a1-e8be-4e06-996f-57844c4a0cc3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13a34ae4-3f82-4559-9b26-b74ba343b2f1",
      "metadata": {
        "id": "13a34ae4-3f82-4559-9b26-b74ba343b2f1"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "81f99047-c287-4f28-a591-114f011a469e",
      "metadata": {
        "id": "81f99047-c287-4f28-a591-114f011a469e",
        "outputId": "88efaa82-6f1a-461f-fb27-9501b8ce61a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9950cb8e-9bb0-4963-82b8-f5ea84c74b65",
      "metadata": {
        "id": "9950cb8e-9bb0-4963-82b8-f5ea84c74b65"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4448b4cd-6d99-4f7f-a23d-b9f94653c4ba",
      "metadata": {
        "id": "4448b4cd-6d99-4f7f-a23d-b9f94653c4ba"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "num_epochs = 150\n",
        "image_size = 72  # We'll resize input images to this size\n",
        "patch_size = 6  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 10\n",
        "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a70a45a7-9302-4a5f-b258-a6247340479f",
      "metadata": {
        "id": "a70a45a7-9302-4a5f-b258-a6247340479f"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ed80a256-0639-473a-9c9e-e1c3a9272990",
      "metadata": {
        "id": "ed80a256-0639-473a-9c9e-e1c3a9272990"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fe74630-1e09-45ca-8ef4-92095f4b9435",
      "metadata": {
        "id": "0fe74630-1e09-45ca-8ef4-92095f4b9435"
      },
      "source": [
        "### Implement multilayer perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e4d1c44b-c024-47d9-82bb-d97d4fca040a",
      "metadata": {
        "id": "e4d1c44b-c024-47d9-82bb-d97d4fca040a"
      },
      "outputs": [],
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2769650-dadb-4698-8a29-cebbb7b7b58b",
      "metadata": {
        "id": "c2769650-dadb-4698-8a29-cebbb7b7b58b"
      },
      "source": [
        "### Implement patch creation as a layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d1b52cc8-afa2-417f-baef-2f0ee67b31c2",
      "metadata": {
        "id": "d1b52cc8-afa2-417f-baef-2f0ee67b31c2"
      },
      "outputs": [],
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c22a76-3fc9-43dd-a4b3-894836b001b6",
      "metadata": {
        "id": "c1c22a76-3fc9-43dd-a4b3-894836b001b6"
      },
      "source": [
        "Let's display patches for a sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6e434a33-f509-4340-9d6e-59ec3c986471",
      "metadata": {
        "id": "6e434a33-f509-4340-9d6e-59ec3c986471",
        "outputId": "b5ccddda-243d-43df-d295-d0118d5b05bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 72 X 72\n",
            "Patch size: 6 X 6\n",
            "Patches per image: 144\n",
            "Elements per patch: 108\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFICAYAAAAyFGczAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAV2UlEQVR4nO3dSXIcWXLGcX8RkZEjCBAEySKLpWa1qlTSBXQcbbTTlWSmnQ6htU4gLVrdrRq7m9UcABBAIoeY3tOC2snc/KMZrSQz/X9rt5eZkYkPsXAPT6WUYgCA/6H6334DAPB/FQEJAA4CEgAcBCQAOAhIAHAQkADgICABwEFAAoCDgAQAR6MW/vM//L1UV9sxrJkn7TUbq4XX01RJ/V8Qv7lhGNUXlco64UPMF2vprKePPwtrlietdFY9G6S6abcPa3b399JZ8/lCqps18U+3lCydNXTxb/bmRnv/h53220iT8NsQh9zGNEl10uXI4l9Ujv+ectF+/2Olvf9R+dtM2vv/u3/8J6mOO0gAcBCQAOAgIAHAQUACgIOABAAHAQkADgISABwEJAA4CEgAcMiTNHWldahXQvd8Mm1CIAn5XakfQZ1KGONJiDKJ71+cpKna+Nre5146yw7xxMfJ4kQ6aurjCRMzszzE12O2PpPOujlqr3ncxZ9znLRJmlq4/ptT7ZotqniqyMzM7ndhSenF31laSnXKvEpO2msqdUU8K4nTL0mYpPnU93zcQQKAg4AEAAcBCQAOAhIAHAQkADgISABwEJAA4CAgAcAhN4qXomVpFnpztfZdsyw0hmYx46dJexT+JHwAcWOEbTbamoRuHX+Ger6Szrqb4rN+vryWzqqS9k199c1fhzV/+dVfSWe9+vmVVPfTDz+GNd2orYx4+fWvw5p291466/Dd76S6TYrXXuxuDtJZvdCob2aWhbIsDnGMwv4G5fXMzHKlxdCU4r+8URwIUXEHCQAOAhIAHAQkADgISABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOfZIma/MjSZi4KWK3vgnrG4o4l5PFSRpls8TJRnvE/cPzjVR3bfE6hfNffSGdtXr2ZVhzebuVzlovtc/5F1/GkyinDx9KZz148VKqe/Lrb8IaZcWAmdn5xWlY87t//RfprJK039lyM4+LxJGz8U4rnHrlimj3TMpf8CTOnKmzL8pknTzmJuIOEgAcBCQAOAhIAHAQkADgICABwEFAAoCDgAQABwEJAA65UVxZpWBmUten3hiqHKY9Vj9V2gdYr+NH4T84E5p8zWw+1z5pOsbNxWPW2p5/9U3cQP2i1hrA53V8LczMqlpp6NeslidS3ebsIi4SHtFvZrbbXoU1/X4vnVUn7ZN2wsqCMtf+PNebeNDAzCzv4t/ZrteuWS6zuEa8/1KzRdgmYjl92ns+7iABwEFAAoCDgAQABwEJAA4CEgAcBCQAOAhIAHAQkADgICABwKFP0qijEEKdOpSTS3xYlT7dhIyZ2WoTTwhM1kln9aP4SYVRguPhIB2lPOa+FadVamF9hpmJ00ziVJE8CaFMfIhrQsZ4SqkSaj7QPmev/BXMhP0fZrYQp3eyMFl0uNE+Z8nx30kRr/+nzANhS8tH4Q4SABwEJAA4CEgAcBCQAOAgIAHAQUACgIOABAAHAQkADgISABzyJM1QaV39TYknViZ1j4zFXf2bVvsIF2ttj8y0jLv1t+JVG2vt/09p4vZ/ZQrCzKwI39NsFk9BmJnV4rKQMsaTRUXcqVNX4jVLwu9RnKqYL1dhzYOLZ9JZ19d/luqmYRfWzKp4h4yZWRJ2ApmZLWZx3elSnH7Zx3tw8qD9ftRs6YW/u7bRzlJxBwkADgISABwEJAA4CEgAcBCQAOAgIAHAQUACgIOABACH3Cg+iVlam9CombVG8bnQBH6y0hrA15XWALsVmthvdnGTr5nZaqZdsyw0PT86P5fOWi/iRv1q0tY3pElrVL67fBXWvH39WjrrwcVTqe7piy/Cmkl9lr/F3/nF08+kk+5+jJvOP7zkfVjSiH8ni0Z7zTzGQxC50b7zsY1/s5O4pqITVimYmTXrRVizXojXX8QdJAA4CEgAcBCQAOAgIAHAQUACgIOABAAHAQkADgISABwEJAA45EkaEx+ZX01x3UJ8Fv7ZLJ6SWXzELJBi1cbd+k9bbWVBm+OpFjOzyy6emCh9/Ih7M7Orn34f1vS9OMlk2ijK5eXPYc33P/wgnfX4s+dSXTnchDX7Y7wKwszMhN9svnonHVUd91Ldw8U6rJmbNtVyIU5Z7a9vw5pue5TOWglrO47CKhEzs06ceErClEwS14mouIMEAAcBCQAOAhIAHAQkADgISABwEJAA4CAgAcBBQAKAg4AEAIc8h1IXrd29FqYSluKuloXQiF+J0wap0l7z5DSeSkjiVFF7FPfgDPGOm/3NtXTWUZhqSeKETNbevp008XmPN9pU0cNW209S7YXrsdemWorwfe6EvTtmZuWoTaI09TI+q2i/2et3V1JdESaL6qR96fUUf09t0uJlVgt7rMxsP8TfU5e1iTMVd5AA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABwyI3irdho3VRxo2kSY7mkuAG5iE3PY9Iexf7u9hDWpGW8lsHMbGZaA2wt1I3H+H2ZmTVj3BzdzrWm7WnUmvDXi/janp/EjdFmZvNKe81yvAlrhrv30llNHf8ZHLbx65mZHTutUXk/j9cHHAfttz302m9jU8d/eKnSt7CEZ5nW9D+JgbAXVoW063hNy8fgDhIAHAQkADgISABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHPokjfgodktx9/yoDZhYV8eTBMLgzgdZe9GdxVMmzz//UnvJt9okR72PH9M/dvHj8s3MdsJqhnRxIZ116LTVElfX78Ka434rnaWus5gLazt68ZptTk7DmjxpEz71eiPV3QqTXW/F95+TNtl1KqxJeCBOzFXCBNs4aVNFeR1PFZmZVcv4b/M4xNM2H4M7SABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHAQkADj056uLDbyjxXUHsbl73sZvb95oqxR2k/aiV33cTJuOYtPwoF2zxTJeR7AS1yQoGyiqRlt/MNto1/bq6k1Y0x+0puc6adesCOsI1Ef+Z2G1xMnpmXRW/ehEqvv+TdzQ/8O9ds3UlQUXwrV9udQiYSmcNRbt76Q5WUt1K+H3ePnmSjpLxR0kADgISABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHAQkADj0SZpam0QZS5y5eamtP6hm8Ws2jfYRbg7xWgMzsz/c3oc1397cSWc9XmlTFX/7zUuhSpuqaNbxlMxspr2vpplLdY+efx3WdIdb6azhqNXVFn+fKWuTHNMUryxoN+L00UJbubDcx+sIKvlvTiqTpuGSOHFmFtd14lFdo+VBu3kQ1oyX2u9HxR0kADgISABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHAQkADjkSZrmRJuqGO8OYU211l52WMYjAlthN4mZ2d0UTy6YmY3CfpKp0/bDHFfaKEFexdMXY69NG8ya+CzxUlhdtBGNR09fxq9ZtBfdb+P9NmZmKe/Cmjxo01NlEKZkhAkxMzPxktnzz56GNd0wSGe9vYz325iZLbfxlEmj/TnZaPHvsRPT5XIfT6+ZmbXX8d/TftR2Gqm4gwQABwEJAA4CEgAcBCQAOAhIAHAQkADgICABwEFAAoBDbhS/OorNnA/ihvL1efyIezOzJw/jurs/ae+rWWiPzP/8dBXWjOJlO3t4KtW18/i9nWy0NQkpxf/z6qS9/5K1/59DHzeBj1lbGVHX4mqDmdCs32pdz1XRhiAUo9ioPFvGTeBfL7XvfLl4JdW9/+7bsGYo2jVLbdwoPiWt0b0kbaDi5uYmrGnbT/ddmnEHCQAuAhIAHAQkADgISABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOeZLmfad1u6+bOHPnRVtZMPXxWftOm1yoZ9r0znIRd+JPWXuu/pdfPJfqNpt44qaqta+qruMJh7oS/y/W2nduc6EuaRMOSf2fLew2KOL3pLxkFidMKnGSJgnrFGZr6Sj7m/Ujqe72QVx3uNXWN9zs4gm2Za9NT+WrrVTXCxNbbSVHmoQ7SABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABw6G3nSduvcrOLu+e3P2md81fTPqzJ4yiddXZ+IdU9Pj0Pax4+0iYXHj39TKprFvHukVTPtLOESZokTtJUlTZJUymDUeLekWLx+//vVxXOEl+ziqdfKnWSJmt1tVI3aZNAzUqr22zi3/bde22S5u6n/wxrzsSvMl/9h1YoOBwOn+wsM+4gAcBFQAKAg4AEAAcBCQAOAhIAHAQkADgISABwEJAA4JAbxZuiNd12U5y5ndjL2Zb47VWmNcne7o5S3WIb1z3/SlulsHz0QqrLwjqFutEaxSuhCTyJDeDqaoZaWM1QxEbxnMT/2VXchayuqbASN4oXsQHcxN9jkVZGaK+ZxDUPZYxf8+wkbiY3M1vex8Mef/z2N9JZozjsoQxBmJhTKu4gAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABwEJAA4CAgAcAhT9KsZzup7mBxV3xqxEfJp/jtNeK0Ry8OQlxu45UR7fkz6az24nOpLls8CdHMtOfXJ2FiRakxM6uS+JrKagN1kqYSJ1GE6R1lqsjMTNi4oE/SCBMyH+rikpy1CZlp6rW6Pr5mdau9/0H423zz9lI6Sxw+sraNd3tUTNIAwC+DgAQABwEJAA4CEgAcBCQAOAhIAHAQkADgICABwCE3ir94sZbq+rd3Yc1u0Bpg20poFJ9pqwimg/ZY9yePnoQ1jz//QjqrWWnXTGmOVtYamJlJfdZi07bcc5s/XXNuEhvFlQ+a1aZtYX2Dmbj+oGi/s5KF96aun6i1z5mFjuxxGLSXrOP3Nmu0QYOi1pX4O8iTuhpDwx0kADgISABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHAQkADj0lQsPN1Ld4uYY1ow7bdrAhAb7PmuPm8+7eJWCmdnpYhnWtAtteidV4oRJI/yfEqdfbIqnJYSBhA916voD06YvFHnUpqyy8CHUlRH9EP8eS9F+ZzZpv7OqxN95JX7n27s3Ul0e4tcUB4FsLqxNef70XDprEP82R2G1x9XdVjpLxR0kADgISABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHAQkADjkSZq3t/GEjJnZdh9PHJRJmxAYcjyhMYqTF424YKU/7MOa3d176ayVVGVmwmROXWn/y3IfX48kTmjkpI3c7HfXYY26U6eptZ/kbr+Li4RpFTOzeRvvDiqmTXu8+sN3Ut2yjSe2zs8eSmd9+9t/k+o6YS/T2Yn2mmMfT6x88fypdFY5auM7hz7Og0qZSvsI3EECgIOABAAHAQkADgISABwEJAA4CEgAcBCQAOAgIAHAITeKv7vWGsWFPnGb19qj8McpbnouScv4qhIfv9/HDcHb20vprN3uTqo7ffIoPuugXf/uNm7gffLsmXTWvoub5s3M3rz6Nqw5Pz+Tzjp9qD2mv7t9Hda8v76Vznr+4mVY0zRa0/zN2x+luqshPm94rDVa399oKxfeX8UDDoflA+msIvxtLsSm7bZoMZSFv825OJCg4g4SABwEJAA4CEgAcBCQAOAgIAHAQUACgIOABAAHAQkADgISABzyJM3de+ER92ZmKT5ySkU6qljcFV+JGT8Jnf9mZu0snrhZzbWpnOvrt1JdVR/CmtvLK+ms7vY+rKkn7bu8O8RTOWZmh9t3Yc37g7am4nD1Z6luv4+nfLpdfF3NzF6P8YTGYql953PTJp7u7uNr+2avTWLNLF5F8KEuHnO7efcn6awmtWHNj6/j34WZtn7CzGy+jJeY7Cdt4knFHSQAOAhIAHAQkADgICABwEFAAoCDgAQABwEJAA4CEgAcBCQAOORJmpNay9LtGE/JZHFtRBb2yDRJm3AoReuwr0r8/qdOm0Q5bLXdNZfvfghr0jhKZy0svh6vvtd2tbTLuVRXD/H0SCdes9uDNv1yEOpW6xPprC7Hv433r7VrNvTa9NEgLG+6P2rf+WTalFgn7BhKwt+vmdl+F08f7W60qaJdLSyyMrMpxde2L+ykAYBfBAEJAA4CEgAcBCQAOAhIAHAQkADgICABwEFAAoBDbhR/uo4fsW5m1m/jps/tpDWjpjpueq6L1ihe1zOp7u3bN2HNb3/z79JZVrQG2O0uXkewmWnXv6rizzmM2iP6k51Kdd1NvBogi43uk9C0bWZ2EFYuNFr/tK3ruCG+dHFjtJnZpDa638aN89OkNT0PRfygJf4Ojvdac/de6JufVdoqha7SPucoDHFov2wdd5AA4CAgAcBBQAKAg4AEAAcBCQAOAhIAHAQkADgISABwEJAA4JAnac7ESZo3fdzVP+60bv06xW8vi6sUkvivoL+Lp0J+/v230lnzpTblUzXCmoeVNi1x38UjDuOkXbNWmGQyM8tD/N6G7hPPOCiXI2sTW7XF12PZipNMWZseSeu4poi7SbI4STOO8WRX3mtnHab4+6yE9R9mZqZ9TVYsvh4psXIBAH4RBCQAOAhIAHAQkADgICABwEFAAoCDgAQABwEJAA65UbxqtZUFYxU/Sr5UYnO3xY+IVxtDU6V1o84HoWn750vprONKu7yPnl2ENcui/S9L0vekNfA2k1a3XAnN0UJjtJnZMGgN5Q9O4+sxm2nXv+/uw5pK7HmeLxZaodD0PA3ayo6s1glDHJvlRjqrW8QrL4Z7bc1Gytr3lISO8kq4rh+DO0gAcBCQAOAgIAHAQUACgIOABAAHAQkADgISABwEJAA4CEgAcMiTNOOoTb9MY9ytLw4l2KzEnfOzonXOz8THus+UdQRZmxBoFtr00QNhemG11B75X9fxB82Tds2aRpsKmS/jSZoiPle/abRJmqaJf7qp0j5nEb5z9Un+g7jmoW3n8VniOpFJ25JgJcfn1ZUWCatV/Nu4P8QTSmZmRbxmyvRRETLjY3AHCQAOAhIAHAQkADgISABwEJAA4CAgAcBBQAKAg4AEAAcBCQAOeZImZ3EnSo673ediLi+EpviFuKtlIU5ytML0QkraZVsKEyZmZpUwpnE8HKSzFst4eqedae9ruVxJdZMwvaBOOJxstJ0oymhLP3TSUas2/pzjpE1PqYMcWZhqacRJoCzueMpDfN5+p43lrFbxZNf6EE8LfXhN7dpKkzTiSSruIAHAQUACgIOABAAHAQkADgISABwEJAA4CEgAcBCQAOCQG8Xve62ZU9i4YJXYzVkJz5KvheZRM7NaXDOQtJ5bSTvXGmWVpucsdiArqwhmrba+YRKf5a9csiy28Paj9jubNco6C+07V7ZsdL22CqJK2kKRvu/DmlS0699U2msq20k6sbnecvya86UWL3mvXdtR+KIm8TtXcQcJAA4CEgAcBCQAOAhIAHAQkADgICABwEFAAoCDgAQABwEJAI5U1GfhA8D/M9xBAoCDgAQABwEJAA4CEgAcBCQAOAhIAHAQkADgICABwEFAAoDjvwD5r6xZwz0pFQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 144 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "868b9aa6-7b50-493c-bfd6-109972dea12f",
      "metadata": {
        "id": "868b9aa6-7b50-493c-bfd6-109972dea12f"
      },
      "source": [
        "### Implement the patch encoding layer\n",
        "\n",
        "The PatchEncoder layer will linearly transform a patch by projecting it into a vector of size projection_dim. In addition, it adds a learnable position embedding to the projected vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "29877509-0ce8-46d2-be6c-1c3353ef9fc9",
      "metadata": {
        "id": "29877509-0ce8-46d2-be6c-1c3353ef9fc9"
      },
      "outputs": [],
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c916faf7-8fc4-426f-b0e5-d397d7f29622",
      "metadata": {
        "id": "c916faf7-8fc4-426f-b0e5-d397d7f29622"
      },
      "source": [
        "### Build the ViT model\n",
        "\n",
        "The ViT model consists of multiple Transformer blocks, which use the layers.MultiHeadAttention layer as a self-attention mechanism applied to the sequence of patches. The Transformer blocks produce a [batch_size, num_patches, projection_dim] tensor, which is processed via an classifier head with softmax to produce the final class probabilities output.\n",
        "\n",
        "Unlike the technique described in the paper, which prepends a learnable embedding to the sequence of encoded patches to serve as the image representation, all the outputs of the final Transformer block are reshaped with layers.Flatten() and used as the image representation input to the classifier head. Note that the layers.GlobalAveragePooling1D layer could also be used instead to aggregate the outputs of the Transformer block, especially when the number of patches and the projection dimensions are large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ae202ac8-765f-4139-ac43-6fe6eb1909c8",
      "metadata": {
        "id": "ae202ac8-765f-4139-ac43-6fe6eb1909c8"
      },
      "outputs": [],
      "source": [
        "def create_vit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac8e6372-eac1-479c-93cd-71700e17716e",
      "metadata": {
        "id": "ac8e6372-eac1-479c-93cd-71700e17716e"
      },
      "source": [
        "### Compile, train, and evaluate the mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e04e8d66-4013-4e62-9840-ab00e7f00184",
      "metadata": {
        "id": "e04e8d66-4013-4e62-9840-ab00e7f00184",
        "outputId": "62983590-ff9d-4be4-be38-08cc9479a679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 119ms/step - accuracy: 0.0289 - loss: 4.8491 - top-5-accuracy: 0.1146 - val_accuracy: 0.1044 - val_loss: 3.9580 - val_top-5-accuracy: 0.3030\n",
            "Epoch 2/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.0780 - loss: 4.0483 - top-5-accuracy: 0.2558 - val_accuracy: 0.1558 - val_loss: 3.6339 - val_top-5-accuracy: 0.3882\n",
            "Epoch 3/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.1094 - loss: 3.7999 - top-5-accuracy: 0.3323 - val_accuracy: 0.1806 - val_loss: 3.4565 - val_top-5-accuracy: 0.4554\n",
            "Epoch 4/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.1407 - loss: 3.6169 - top-5-accuracy: 0.3867 - val_accuracy: 0.2116 - val_loss: 3.3442 - val_top-5-accuracy: 0.4764\n",
            "Epoch 5/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.1644 - loss: 3.4439 - top-5-accuracy: 0.4332 - val_accuracy: 0.2426 - val_loss: 3.1022 - val_top-5-accuracy: 0.5342\n",
            "Epoch 6/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.2012 - loss: 3.2615 - top-5-accuracy: 0.4862 - val_accuracy: 0.2580 - val_loss: 2.9621 - val_top-5-accuracy: 0.5642\n",
            "Epoch 7/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.2311 - loss: 3.1144 - top-5-accuracy: 0.5269 - val_accuracy: 0.2920 - val_loss: 2.8184 - val_top-5-accuracy: 0.6000\n",
            "Epoch 8/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.2602 - loss: 2.9556 - top-5-accuracy: 0.5673 - val_accuracy: 0.3240 - val_loss: 2.6808 - val_top-5-accuracy: 0.6344\n",
            "Epoch 9/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.2883 - loss: 2.8049 - top-5-accuracy: 0.6039 - val_accuracy: 0.3444 - val_loss: 2.5694 - val_top-5-accuracy: 0.6562\n",
            "Epoch 10/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.3136 - loss: 2.6765 - top-5-accuracy: 0.6351 - val_accuracy: 0.3632 - val_loss: 2.4832 - val_top-5-accuracy: 0.6722\n",
            "Epoch 11/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.3369 - loss: 2.5814 - top-5-accuracy: 0.6555 - val_accuracy: 0.3778 - val_loss: 2.4107 - val_top-5-accuracy: 0.6870\n",
            "Epoch 12/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.3520 - loss: 2.4998 - top-5-accuracy: 0.6730 - val_accuracy: 0.3818 - val_loss: 2.3652 - val_top-5-accuracy: 0.6988\n",
            "Epoch 13/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.3724 - loss: 2.4057 - top-5-accuracy: 0.6923 - val_accuracy: 0.4016 - val_loss: 2.3011 - val_top-5-accuracy: 0.7060\n",
            "Epoch 14/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.3838 - loss: 2.3505 - top-5-accuracy: 0.7038 - val_accuracy: 0.4148 - val_loss: 2.2723 - val_top-5-accuracy: 0.7104\n",
            "Epoch 15/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.3948 - loss: 2.2909 - top-5-accuracy: 0.7179 - val_accuracy: 0.4196 - val_loss: 2.2157 - val_top-5-accuracy: 0.7250\n",
            "Epoch 16/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.4089 - loss: 2.2150 - top-5-accuracy: 0.7336 - val_accuracy: 0.4210 - val_loss: 2.2275 - val_top-5-accuracy: 0.7186\n",
            "Epoch 17/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.4251 - loss: 2.1593 - top-5-accuracy: 0.7473 - val_accuracy: 0.4354 - val_loss: 2.1542 - val_top-5-accuracy: 0.7352\n",
            "Epoch 18/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.4376 - loss: 2.0971 - top-5-accuracy: 0.7541 - val_accuracy: 0.4384 - val_loss: 2.1329 - val_top-5-accuracy: 0.7432\n",
            "Epoch 19/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.4442 - loss: 2.0533 - top-5-accuracy: 0.7621 - val_accuracy: 0.4578 - val_loss: 2.0653 - val_top-5-accuracy: 0.7574\n",
            "Epoch 20/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.4513 - loss: 2.0106 - top-5-accuracy: 0.7731 - val_accuracy: 0.4438 - val_loss: 2.0876 - val_top-5-accuracy: 0.7550\n",
            "Epoch 21/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.4683 - loss: 1.9354 - top-5-accuracy: 0.7889 - val_accuracy: 0.4504 - val_loss: 2.0583 - val_top-5-accuracy: 0.7620\n",
            "Epoch 22/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.4819 - loss: 1.8974 - top-5-accuracy: 0.7916 - val_accuracy: 0.4620 - val_loss: 2.0208 - val_top-5-accuracy: 0.7644\n",
            "Epoch 23/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.4927 - loss: 1.8416 - top-5-accuracy: 0.8019 - val_accuracy: 0.4810 - val_loss: 1.9820 - val_top-5-accuracy: 0.7696\n",
            "Epoch 24/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.5014 - loss: 1.8037 - top-5-accuracy: 0.8112 - val_accuracy: 0.4756 - val_loss: 1.9786 - val_top-5-accuracy: 0.7718\n",
            "Epoch 25/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.5113 - loss: 1.7659 - top-5-accuracy: 0.8180 - val_accuracy: 0.4776 - val_loss: 1.9858 - val_top-5-accuracy: 0.7708\n",
            "Epoch 26/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.5251 - loss: 1.7093 - top-5-accuracy: 0.8280 - val_accuracy: 0.4864 - val_loss: 1.9591 - val_top-5-accuracy: 0.7810\n",
            "Epoch 27/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.5321 - loss: 1.6925 - top-5-accuracy: 0.8286 - val_accuracy: 0.4892 - val_loss: 1.9385 - val_top-5-accuracy: 0.7838\n",
            "Epoch 28/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.5324 - loss: 1.6739 - top-5-accuracy: 0.8345 - val_accuracy: 0.4928 - val_loss: 1.9305 - val_top-5-accuracy: 0.7886\n",
            "Epoch 29/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.5448 - loss: 1.6214 - top-5-accuracy: 0.8427 - val_accuracy: 0.4976 - val_loss: 1.9231 - val_top-5-accuracy: 0.7852\n",
            "Epoch 30/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.5557 - loss: 1.5899 - top-5-accuracy: 0.8457 - val_accuracy: 0.5030 - val_loss: 1.9333 - val_top-5-accuracy: 0.7926\n",
            "Epoch 31/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.5625 - loss: 1.5506 - top-5-accuracy: 0.8537 - val_accuracy: 0.4986 - val_loss: 1.9102 - val_top-5-accuracy: 0.7946\n",
            "Epoch 32/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.5732 - loss: 1.5196 - top-5-accuracy: 0.8571 - val_accuracy: 0.5032 - val_loss: 1.9061 - val_top-5-accuracy: 0.7916\n",
            "Epoch 33/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.5778 - loss: 1.4921 - top-5-accuracy: 0.8612 - val_accuracy: 0.4984 - val_loss: 1.8858 - val_top-5-accuracy: 0.7984\n",
            "Epoch 34/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.5823 - loss: 1.4585 - top-5-accuracy: 0.8705 - val_accuracy: 0.5066 - val_loss: 1.8856 - val_top-5-accuracy: 0.7984\n",
            "Epoch 35/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.5923 - loss: 1.4296 - top-5-accuracy: 0.8742 - val_accuracy: 0.5130 - val_loss: 1.8763 - val_top-5-accuracy: 0.8010\n",
            "Epoch 36/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.5945 - loss: 1.4193 - top-5-accuracy: 0.8791 - val_accuracy: 0.5098 - val_loss: 1.8879 - val_top-5-accuracy: 0.8000\n",
            "Epoch 37/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6018 - loss: 1.3954 - top-5-accuracy: 0.8783 - val_accuracy: 0.5076 - val_loss: 1.8976 - val_top-5-accuracy: 0.7964\n",
            "Epoch 38/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.6115 - loss: 1.3486 - top-5-accuracy: 0.8856 - val_accuracy: 0.5152 - val_loss: 1.8600 - val_top-5-accuracy: 0.8008\n",
            "Epoch 39/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6103 - loss: 1.3448 - top-5-accuracy: 0.8865 - val_accuracy: 0.5140 - val_loss: 1.8891 - val_top-5-accuracy: 0.7980\n",
            "Epoch 40/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.6190 - loss: 1.3140 - top-5-accuracy: 0.8924 - val_accuracy: 0.5180 - val_loss: 1.9051 - val_top-5-accuracy: 0.8020\n",
            "Epoch 41/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.6242 - loss: 1.2884 - top-5-accuracy: 0.8959 - val_accuracy: 0.5154 - val_loss: 1.8845 - val_top-5-accuracy: 0.8004\n",
            "Epoch 42/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.6411 - loss: 1.2543 - top-5-accuracy: 0.8982 - val_accuracy: 0.5204 - val_loss: 1.8842 - val_top-5-accuracy: 0.8062\n",
            "Epoch 43/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6371 - loss: 1.2471 - top-5-accuracy: 0.9030 - val_accuracy: 0.5192 - val_loss: 1.9057 - val_top-5-accuracy: 0.8004\n",
            "Epoch 44/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.6470 - loss: 1.2173 - top-5-accuracy: 0.9036 - val_accuracy: 0.5220 - val_loss: 1.8924 - val_top-5-accuracy: 0.8044\n",
            "Epoch 45/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.6502 - loss: 1.2021 - top-5-accuracy: 0.9076 - val_accuracy: 0.5222 - val_loss: 1.8930 - val_top-5-accuracy: 0.8036\n",
            "Epoch 46/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6578 - loss: 1.1754 - top-5-accuracy: 0.9100 - val_accuracy: 0.5220 - val_loss: 1.9022 - val_top-5-accuracy: 0.8004\n",
            "Epoch 47/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6539 - loss: 1.1933 - top-5-accuracy: 0.9076 - val_accuracy: 0.5210 - val_loss: 1.8861 - val_top-5-accuracy: 0.8064\n",
            "Epoch 48/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 111ms/step - accuracy: 0.6586 - loss: 1.1649 - top-5-accuracy: 0.9121 - val_accuracy: 0.5232 - val_loss: 1.9122 - val_top-5-accuracy: 0.8054\n",
            "Epoch 49/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6673 - loss: 1.1300 - top-5-accuracy: 0.9163 - val_accuracy: 0.5230 - val_loss: 1.9157 - val_top-5-accuracy: 0.8022\n",
            "Epoch 50/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.6713 - loss: 1.1189 - top-5-accuracy: 0.9210 - val_accuracy: 0.5252 - val_loss: 1.9241 - val_top-5-accuracy: 0.8092\n",
            "Epoch 51/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.6725 - loss: 1.1101 - top-5-accuracy: 0.9179 - val_accuracy: 0.5304 - val_loss: 1.8649 - val_top-5-accuracy: 0.8132\n",
            "Epoch 52/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6745 - loss: 1.0983 - top-5-accuracy: 0.9225 - val_accuracy: 0.5232 - val_loss: 1.8690 - val_top-5-accuracy: 0.8088\n",
            "Epoch 53/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6835 - loss: 1.0704 - top-5-accuracy: 0.9249 - val_accuracy: 0.5240 - val_loss: 1.9282 - val_top-5-accuracy: 0.8068\n",
            "Epoch 54/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.6913 - loss: 1.0422 - top-5-accuracy: 0.9277 - val_accuracy: 0.5332 - val_loss: 1.9074 - val_top-5-accuracy: 0.8096\n",
            "Epoch 55/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6889 - loss: 1.0559 - top-5-accuracy: 0.9252 - val_accuracy: 0.5298 - val_loss: 1.9066 - val_top-5-accuracy: 0.8118\n",
            "Epoch 56/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6906 - loss: 1.0390 - top-5-accuracy: 0.9295 - val_accuracy: 0.5244 - val_loss: 1.9347 - val_top-5-accuracy: 0.8102\n",
            "Epoch 57/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7020 - loss: 1.0037 - top-5-accuracy: 0.9348 - val_accuracy: 0.5264 - val_loss: 1.9237 - val_top-5-accuracy: 0.8078\n",
            "Epoch 58/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7043 - loss: 0.9880 - top-5-accuracy: 0.9344 - val_accuracy: 0.5288 - val_loss: 1.9257 - val_top-5-accuracy: 0.8108\n",
            "Epoch 59/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7061 - loss: 0.9870 - top-5-accuracy: 0.9351 - val_accuracy: 0.5276 - val_loss: 1.9242 - val_top-5-accuracy: 0.8106\n",
            "Epoch 60/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7133 - loss: 0.9662 - top-5-accuracy: 0.9367 - val_accuracy: 0.5252 - val_loss: 1.9653 - val_top-5-accuracy: 0.8076\n",
            "Epoch 61/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7136 - loss: 0.9627 - top-5-accuracy: 0.9369 - val_accuracy: 0.5322 - val_loss: 1.9311 - val_top-5-accuracy: 0.8088\n",
            "Epoch 62/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 109ms/step - accuracy: 0.7183 - loss: 0.9520 - top-5-accuracy: 0.9388 - val_accuracy: 0.5338 - val_loss: 1.8821 - val_top-5-accuracy: 0.8108\n",
            "Epoch 63/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7188 - loss: 0.9376 - top-5-accuracy: 0.9410 - val_accuracy: 0.5316 - val_loss: 1.9027 - val_top-5-accuracy: 0.8156\n",
            "Epoch 64/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7217 - loss: 0.9337 - top-5-accuracy: 0.9429 - val_accuracy: 0.5272 - val_loss: 1.9559 - val_top-5-accuracy: 0.8100\n",
            "Epoch 65/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7239 - loss: 0.9159 - top-5-accuracy: 0.9430 - val_accuracy: 0.5288 - val_loss: 1.9409 - val_top-5-accuracy: 0.8102\n",
            "Epoch 66/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7268 - loss: 0.9112 - top-5-accuracy: 0.9455 - val_accuracy: 0.5324 - val_loss: 1.9391 - val_top-5-accuracy: 0.8112\n",
            "Epoch 67/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7236 - loss: 0.9230 - top-5-accuracy: 0.9429 - val_accuracy: 0.5322 - val_loss: 1.9536 - val_top-5-accuracy: 0.8114\n",
            "Epoch 68/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.6363 - loss: 1.3008 - top-5-accuracy: 0.8959 - val_accuracy: 0.5258 - val_loss: 1.9075 - val_top-5-accuracy: 0.8098\n",
            "Epoch 69/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7154 - loss: 0.9514 - top-5-accuracy: 0.9407 - val_accuracy: 0.5318 - val_loss: 1.9124 - val_top-5-accuracy: 0.8124\n",
            "Epoch 70/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7279 - loss: 0.9121 - top-5-accuracy: 0.9441 - val_accuracy: 0.5326 - val_loss: 1.9098 - val_top-5-accuracy: 0.8144\n",
            "Epoch 71/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7302 - loss: 0.8898 - top-5-accuracy: 0.9478 - val_accuracy: 0.5332 - val_loss: 1.9200 - val_top-5-accuracy: 0.8158\n",
            "Epoch 72/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.7388 - loss: 0.8690 - top-5-accuracy: 0.9506 - val_accuracy: 0.5368 - val_loss: 1.9358 - val_top-5-accuracy: 0.8142\n",
            "Epoch 73/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7460 - loss: 0.8403 - top-5-accuracy: 0.9528 - val_accuracy: 0.5328 - val_loss: 1.9280 - val_top-5-accuracy: 0.8126\n",
            "Epoch 74/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7482 - loss: 0.8313 - top-5-accuracy: 0.9525 - val_accuracy: 0.5310 - val_loss: 1.9767 - val_top-5-accuracy: 0.8176\n",
            "Epoch 75/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7451 - loss: 0.8510 - top-5-accuracy: 0.9516 - val_accuracy: 0.5328 - val_loss: 1.9558 - val_top-5-accuracy: 0.8110\n",
            "Epoch 76/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7513 - loss: 0.8311 - top-5-accuracy: 0.9530 - val_accuracy: 0.5352 - val_loss: 1.9631 - val_top-5-accuracy: 0.8114\n",
            "Epoch 77/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.7508 - loss: 0.8169 - top-5-accuracy: 0.9555 - val_accuracy: 0.5392 - val_loss: 1.9407 - val_top-5-accuracy: 0.8186\n",
            "Epoch 78/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7552 - loss: 0.8182 - top-5-accuracy: 0.9552 - val_accuracy: 0.5352 - val_loss: 1.9429 - val_top-5-accuracy: 0.8168\n",
            "Epoch 79/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7557 - loss: 0.8067 - top-5-accuracy: 0.9574 - val_accuracy: 0.5336 - val_loss: 1.9681 - val_top-5-accuracy: 0.8150\n",
            "Epoch 80/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7583 - loss: 0.7939 - top-5-accuracy: 0.9549 - val_accuracy: 0.5370 - val_loss: 1.9319 - val_top-5-accuracy: 0.8184\n",
            "Epoch 81/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7662 - loss: 0.7814 - top-5-accuracy: 0.9587 - val_accuracy: 0.5380 - val_loss: 1.9650 - val_top-5-accuracy: 0.8124\n",
            "Epoch 82/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7554 - loss: 0.7994 - top-5-accuracy: 0.9565 - val_accuracy: 0.5354 - val_loss: 1.9717 - val_top-5-accuracy: 0.8118\n",
            "Epoch 83/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.7623 - loss: 0.7847 - top-5-accuracy: 0.9581 - val_accuracy: 0.5404 - val_loss: 1.9726 - val_top-5-accuracy: 0.8162\n",
            "Epoch 84/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.7618 - loss: 0.7844 - top-5-accuracy: 0.9583 - val_accuracy: 0.5426 - val_loss: 1.9717 - val_top-5-accuracy: 0.8150\n",
            "Epoch 85/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7711 - loss: 0.7427 - top-5-accuracy: 0.9631 - val_accuracy: 0.5358 - val_loss: 2.0004 - val_top-5-accuracy: 0.8128\n",
            "Epoch 86/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7628 - loss: 0.7687 - top-5-accuracy: 0.9619 - val_accuracy: 0.5388 - val_loss: 1.9881 - val_top-5-accuracy: 0.8130\n",
            "Epoch 87/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7679 - loss: 0.7651 - top-5-accuracy: 0.9597 - val_accuracy: 0.5418 - val_loss: 1.9836 - val_top-5-accuracy: 0.8190\n",
            "Epoch 88/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7681 - loss: 0.7517 - top-5-accuracy: 0.9619 - val_accuracy: 0.5348 - val_loss: 2.0218 - val_top-5-accuracy: 0.8122\n",
            "Epoch 89/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7785 - loss: 0.7298 - top-5-accuracy: 0.9651 - val_accuracy: 0.5326 - val_loss: 2.0068 - val_top-5-accuracy: 0.8100\n",
            "Epoch 90/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7759 - loss: 0.7337 - top-5-accuracy: 0.9626 - val_accuracy: 0.5380 - val_loss: 2.0040 - val_top-5-accuracy: 0.8158\n",
            "Epoch 91/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7803 - loss: 0.7156 - top-5-accuracy: 0.9659 - val_accuracy: 0.5328 - val_loss: 1.9958 - val_top-5-accuracy: 0.8138\n",
            "Epoch 92/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7804 - loss: 0.7147 - top-5-accuracy: 0.9652 - val_accuracy: 0.5362 - val_loss: 2.0377 - val_top-5-accuracy: 0.8126\n",
            "Epoch 93/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.7792 - loss: 0.7185 - top-5-accuracy: 0.9659 - val_accuracy: 0.5452 - val_loss: 1.9902 - val_top-5-accuracy: 0.8154\n",
            "Epoch 94/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7840 - loss: 0.7116 - top-5-accuracy: 0.9645 - val_accuracy: 0.5382 - val_loss: 2.0003 - val_top-5-accuracy: 0.8130\n",
            "Epoch 95/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7777 - loss: 0.7244 - top-5-accuracy: 0.9644 - val_accuracy: 0.5436 - val_loss: 2.0016 - val_top-5-accuracy: 0.8162\n",
            "Epoch 96/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.6161 - loss: 1.4408 - top-5-accuracy: 0.8669 - val_accuracy: 0.5168 - val_loss: 2.0062 - val_top-5-accuracy: 0.7950\n",
            "Epoch 97/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7303 - loss: 0.8967 - top-5-accuracy: 0.9493 - val_accuracy: 0.5356 - val_loss: 1.9810 - val_top-5-accuracy: 0.8118\n",
            "Epoch 98/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7610 - loss: 0.8030 - top-5-accuracy: 0.9574 - val_accuracy: 0.5306 - val_loss: 2.0222 - val_top-5-accuracy: 0.8130\n",
            "Epoch 99/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7674 - loss: 0.7579 - top-5-accuracy: 0.9623 - val_accuracy: 0.5340 - val_loss: 2.0557 - val_top-5-accuracy: 0.8128\n",
            "Epoch 100/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7762 - loss: 0.7327 - top-5-accuracy: 0.9634 - val_accuracy: 0.5408 - val_loss: 2.0112 - val_top-5-accuracy: 0.8160\n",
            "Epoch 101/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7877 - loss: 0.6987 - top-5-accuracy: 0.9664 - val_accuracy: 0.5328 - val_loss: 2.0324 - val_top-5-accuracy: 0.8130\n",
            "Epoch 102/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.7861 - loss: 0.6928 - top-5-accuracy: 0.9687 - val_accuracy: 0.5404 - val_loss: 2.0321 - val_top-5-accuracy: 0.8170\n",
            "Epoch 103/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7922 - loss: 0.6784 - top-5-accuracy: 0.9690 - val_accuracy: 0.5402 - val_loss: 2.0396 - val_top-5-accuracy: 0.8156\n",
            "Epoch 104/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7944 - loss: 0.6687 - top-5-accuracy: 0.9699 - val_accuracy: 0.5372 - val_loss: 2.0440 - val_top-5-accuracy: 0.8154\n",
            "Epoch 105/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.8021 - loss: 0.6505 - top-5-accuracy: 0.9709 - val_accuracy: 0.5396 - val_loss: 2.0386 - val_top-5-accuracy: 0.8144\n",
            "Epoch 106/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.8019 - loss: 0.6549 - top-5-accuracy: 0.9698 - val_accuracy: 0.5398 - val_loss: 2.0242 - val_top-5-accuracy: 0.8196\n",
            "Epoch 107/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7962 - loss: 0.6603 - top-5-accuracy: 0.9695 - val_accuracy: 0.5392 - val_loss: 2.0424 - val_top-5-accuracy: 0.8152\n",
            "Epoch 108/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8011 - loss: 0.6492 - top-5-accuracy: 0.9712 - val_accuracy: 0.5270 - val_loss: 2.0958 - val_top-5-accuracy: 0.8084\n",
            "Epoch 109/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.7979 - loss: 0.6611 - top-5-accuracy: 0.9698 - val_accuracy: 0.5414 - val_loss: 2.0481 - val_top-5-accuracy: 0.8164\n",
            "Epoch 110/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8053 - loss: 0.6386 - top-5-accuracy: 0.9708 - val_accuracy: 0.5406 - val_loss: 2.0552 - val_top-5-accuracy: 0.8136\n",
            "Epoch 111/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.8014 - loss: 0.6454 - top-5-accuracy: 0.9718 - val_accuracy: 0.5508 - val_loss: 2.0819 - val_top-5-accuracy: 0.8160\n",
            "Epoch 112/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8041 - loss: 0.6330 - top-5-accuracy: 0.9721 - val_accuracy: 0.5352 - val_loss: 2.0413 - val_top-5-accuracy: 0.8104\n",
            "Epoch 113/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8057 - loss: 0.6387 - top-5-accuracy: 0.9708 - val_accuracy: 0.5430 - val_loss: 2.0722 - val_top-5-accuracy: 0.8174\n",
            "Epoch 114/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8038 - loss: 0.6391 - top-5-accuracy: 0.9715 - val_accuracy: 0.5418 - val_loss: 2.0926 - val_top-5-accuracy: 0.8186\n",
            "Epoch 115/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.8010 - loss: 0.6504 - top-5-accuracy: 0.9708 - val_accuracy: 0.5360 - val_loss: 2.1113 - val_top-5-accuracy: 0.8178\n",
            "Epoch 116/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8095 - loss: 0.6115 - top-5-accuracy: 0.9763 - val_accuracy: 0.5418 - val_loss: 2.0544 - val_top-5-accuracy: 0.8196\n",
            "Epoch 117/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8096 - loss: 0.6233 - top-5-accuracy: 0.9732 - val_accuracy: 0.5360 - val_loss: 2.1244 - val_top-5-accuracy: 0.8128\n",
            "Epoch 118/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8120 - loss: 0.6075 - top-5-accuracy: 0.9753 - val_accuracy: 0.5454 - val_loss: 2.0959 - val_top-5-accuracy: 0.8188\n",
            "Epoch 119/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8033 - loss: 0.6344 - top-5-accuracy: 0.9744 - val_accuracy: 0.5446 - val_loss: 2.1031 - val_top-5-accuracy: 0.8186\n",
            "Epoch 120/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8109 - loss: 0.6175 - top-5-accuracy: 0.9737 - val_accuracy: 0.5288 - val_loss: 2.1010 - val_top-5-accuracy: 0.8144\n",
            "Epoch 121/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8131 - loss: 0.6048 - top-5-accuracy: 0.9748 - val_accuracy: 0.5408 - val_loss: 2.1335 - val_top-5-accuracy: 0.8188\n",
            "Epoch 122/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8120 - loss: 0.6151 - top-5-accuracy: 0.9730 - val_accuracy: 0.5418 - val_loss: 2.0691 - val_top-5-accuracy: 0.8194\n",
            "Epoch 123/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8117 - loss: 0.6060 - top-5-accuracy: 0.9753 - val_accuracy: 0.5458 - val_loss: 2.0627 - val_top-5-accuracy: 0.8218\n",
            "Epoch 124/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8162 - loss: 0.5932 - top-5-accuracy: 0.9756 - val_accuracy: 0.5316 - val_loss: 2.0655 - val_top-5-accuracy: 0.8096\n",
            "Epoch 125/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.8155 - loss: 0.6028 - top-5-accuracy: 0.9755 - val_accuracy: 0.5398 - val_loss: 2.1323 - val_top-5-accuracy: 0.8206\n",
            "Epoch 126/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8143 - loss: 0.6091 - top-5-accuracy: 0.9744 - val_accuracy: 0.5466 - val_loss: 2.0379 - val_top-5-accuracy: 0.8180\n",
            "Epoch 127/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8178 - loss: 0.5919 - top-5-accuracy: 0.9746 - val_accuracy: 0.5388 - val_loss: 2.1070 - val_top-5-accuracy: 0.8116\n",
            "Epoch 128/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8141 - loss: 0.6111 - top-5-accuracy: 0.9747 - val_accuracy: 0.5378 - val_loss: 2.0774 - val_top-5-accuracy: 0.8168\n",
            "Epoch 129/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8217 - loss: 0.5903 - top-5-accuracy: 0.9754 - val_accuracy: 0.5442 - val_loss: 2.0972 - val_top-5-accuracy: 0.8166\n",
            "Epoch 130/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8212 - loss: 0.5829 - top-5-accuracy: 0.9773 - val_accuracy: 0.5396 - val_loss: 2.0920 - val_top-5-accuracy: 0.8176\n",
            "Epoch 131/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8180 - loss: 0.5943 - top-5-accuracy: 0.9763 - val_accuracy: 0.5434 - val_loss: 2.0784 - val_top-5-accuracy: 0.8182\n",
            "Epoch 132/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8184 - loss: 0.5956 - top-5-accuracy: 0.9754 - val_accuracy: 0.5340 - val_loss: 2.1080 - val_top-5-accuracy: 0.8094\n",
            "Epoch 133/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8220 - loss: 0.5788 - top-5-accuracy: 0.9769 - val_accuracy: 0.5328 - val_loss: 2.0812 - val_top-5-accuracy: 0.8114\n",
            "Epoch 134/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.8235 - loss: 0.5692 - top-5-accuracy: 0.9780 - val_accuracy: 0.5440 - val_loss: 2.0729 - val_top-5-accuracy: 0.8172\n",
            "Epoch 135/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 104ms/step - accuracy: 0.8240 - loss: 0.5754 - top-5-accuracy: 0.9767 - val_accuracy: 0.5336 - val_loss: 2.1537 - val_top-5-accuracy: 0.8166\n",
            "Epoch 136/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8222 - loss: 0.5815 - top-5-accuracy: 0.9780 - val_accuracy: 0.5386 - val_loss: 2.0955 - val_top-5-accuracy: 0.8188\n",
            "Epoch 137/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8199 - loss: 0.5845 - top-5-accuracy: 0.9773 - val_accuracy: 0.5342 - val_loss: 2.1701 - val_top-5-accuracy: 0.8118\n",
            "Epoch 138/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8255 - loss: 0.5687 - top-5-accuracy: 0.9790 - val_accuracy: 0.5436 - val_loss: 2.1201 - val_top-5-accuracy: 0.8138\n",
            "Epoch 139/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8275 - loss: 0.5672 - top-5-accuracy: 0.9760 - val_accuracy: 0.5448 - val_loss: 2.1992 - val_top-5-accuracy: 0.8160\n",
            "Epoch 140/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8229 - loss: 0.5776 - top-5-accuracy: 0.9776 - val_accuracy: 0.5456 - val_loss: 2.0691 - val_top-5-accuracy: 0.8174\n",
            "Epoch 141/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8278 - loss: 0.5604 - top-5-accuracy: 0.9804 - val_accuracy: 0.5468 - val_loss: 2.1388 - val_top-5-accuracy: 0.8142\n",
            "Epoch 142/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8267 - loss: 0.5661 - top-5-accuracy: 0.9779 - val_accuracy: 0.5412 - val_loss: 2.1559 - val_top-5-accuracy: 0.8154\n",
            "Epoch 143/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8281 - loss: 0.5622 - top-5-accuracy: 0.9786 - val_accuracy: 0.5350 - val_loss: 2.1609 - val_top-5-accuracy: 0.8120\n",
            "Epoch 144/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8327 - loss: 0.5547 - top-5-accuracy: 0.9789 - val_accuracy: 0.5314 - val_loss: 2.1956 - val_top-5-accuracy: 0.8148\n",
            "Epoch 145/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8324 - loss: 0.5551 - top-5-accuracy: 0.9786 - val_accuracy: 0.5416 - val_loss: 2.1200 - val_top-5-accuracy: 0.8154\n",
            "Epoch 146/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8315 - loss: 0.5499 - top-5-accuracy: 0.9796 - val_accuracy: 0.5384 - val_loss: 2.1956 - val_top-5-accuracy: 0.8154\n",
            "Epoch 147/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8321 - loss: 0.5397 - top-5-accuracy: 0.9791 - val_accuracy: 0.5424 - val_loss: 2.1640 - val_top-5-accuracy: 0.8174\n",
            "Epoch 148/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8337 - loss: 0.5523 - top-5-accuracy: 0.9784 - val_accuracy: 0.5382 - val_loss: 2.2246 - val_top-5-accuracy: 0.8142\n",
            "Epoch 149/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8334 - loss: 0.5475 - top-5-accuracy: 0.9776 - val_accuracy: 0.5386 - val_loss: 2.1488 - val_top-5-accuracy: 0.8124\n",
            "Epoch 150/150\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 105ms/step - accuracy: 0.8357 - loss: 0.5327 - top-5-accuracy: 0.9802 - val_accuracy: 0.5458 - val_loss: 2.1487 - val_top-5-accuracy: 0.8134\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5571 - loss: 2.0059 - top-5-accuracy: 0.8111\n",
            "Test accuracy: 55.56%\n",
            "Test top 5 accuracy: 81.34%\n"
          ]
        }
      ],
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"./checkpoint.weights.h5\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "vit_classifier = create_vit_classifier()\n",
        "history = run_experiment(vit_classifier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72405065-f6db-49ee-8af8-daffcd6ad304",
      "metadata": {
        "id": "72405065-f6db-49ee-8af8-daffcd6ad304"
      },
      "source": [
        "After 100 epochs, the ViT model achieves around 55% accuracy and 82% top-5 accuracy on the test data. These are not competitive results on the CIFAR-100 dataset, as a ResNet50V2 trained from scratch on the same data can achieve 67% accuracy.\n",
        "\n",
        "Note that the state of the art results reported in the paper are achieved by pre-training the ViT model using the JFT-300M dataset, then fine-tuning it on the target dataset. To improve the model quality without pre-training, you can try to train the model for more epochs, use a larger number of Transformer layers, resize the input images, change the patch size, or increase the projection dimensions. Besides, as mentioned in the paper, the quality of the model is affected not only by architecture choices, but also by parameters such as the learning rate schedule, optimizer, weight decay, etc. In practice, it's recommended to fine-tune a ViT model that was pre-trained using a large, high-resolution dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c46283-3efe-4345-ba6c-0b79b235f9ee",
      "metadata": {
        "id": "d9c46283-3efe-4345-ba6c-0b79b235f9ee"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}